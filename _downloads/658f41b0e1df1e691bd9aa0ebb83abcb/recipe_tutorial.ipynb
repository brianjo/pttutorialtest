{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nLoading data in PyTorch\n=======================\n\nPyTorch features extensive neural network building blocks with a simple,\nintuitive, and stable API. PyTorch includes packages to prepare and load\ncommon datasets for your model.\n\nIntroduction\n------------\n\nAt the heart of PyTorch data loading utility is the\n``torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader>``\\ **class.\nIt represents a Python iterable over a dataset. Libraries in PyTorch\noffer built-in high-quality datasets for you to use in\n``torch.utils.data.Dataset <https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset>``**.\nThese datasets are currently available in:\n\n-  ``torchvision <https://pytorch.org/docs/stable/torchvision/datasets.html>``\\ \\_\\_\n-  ``torchaudio <https://pytorch.org/audio/datasets.html>``\\ \\_\\_\n-  ``torchtext <https://pytorch.org/text/datasets.html>``\\ \\_\\_\n\nwith more to come. Using the Yesno dataset from\n``torchaudio.datasets.YESNO``, we will demonstrate how to effectively\nand efficiently load data from a PyTorch ``Dataset`` into a PyTorch\n``DataLoader``.\n\nSetup\n-----\n\nBefore we begin, we need to install ``torchaudio`` to have access to the\ndataset.\n\n::\n\n      pip install torchaudio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Steps\n-----\n\n1. Import all necessary libraries for loading our data\n2. Access the data in the dataset\n3. Loading the data\n4. Iterate over the data\n5. [Optional] Visualize the data\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Import necessary libraries for loading our data\n==================================================\n\nFor this recipe, we will use ``torch`` and ``torchaudio``. Depending on\nwhat built-in datasets you use, you can also install and import\n``torchvision`` or ``torchtext``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Uncomment the line below to enable this in Google Colab\n# !pip install torch torchaudio torchvision torchtext\n\nimport torch\nimport torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Access the data in the dataset\n=================================\n\nThe Yesno dataset in ``torchaudio`` features sixty recordings of one\nindividual saying yes or no in Hebrew; with each recording being eight\nwords long (``read more here <https://www.openslr.org/1/>``\\ \\__).\n\n``torchaudio.datasets.YESNO`` creates a dataset for YesNo.\n\n.. code:: python\n\n      torchaudio.datasets.YESNO(\n        root,\n        url='http://www.openslr.org/resources/1/waves_yesno.tar.gz',\n        folder_in_archive='waves_yesno',\n        download=False,\n        transform=None,\n        target_transform=None)\n\nEach item in the dataset is a tuple of the form: (waveform, sample_rate,\nlabels).\n\nYou must set a ``root`` for the Yesno dataset, which is where the\ntraining and testing dataset will exist. The other parameters are\noptional, with their default values shown. Here is some additional\nuseful info on the other parameters:\n\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-  ``download``: If true, downloads the dataset from the internet and\n   puts it in root directory. If dataset is already downloaded, it is\n   not downloaded again.\n-  ``transform``: Using transforms on your data allows you to take it\n   from its source state and transform it into data that\u2019s joined\n   together, de-normalized, and ready for training. Each library in\n   PyTorch supports a growing list of transformations.\n-  ``target_transform``: A function/transform that takes in the target\n   and transforms it.\n\nLet\u2019s access our Yesno data:\n\nA data point in Yesno is a tuple (waveform, sample_rate, labels) where\nlabels is a list of integers with 1 for yes and 0 for no.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "yesno_data = torchaudio.datasets.YESNO('./', download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pick data point number 3 to see an example of the the yesno_data:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n = 3\nwaveform, sample_rate, labels = yesno_data[n]\nprint(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When using this data in practice, it is best practice to provision the\ndata into a \u201ctraining\u201d dataset and a \u201ctesting\u201d dataset. This ensures\nthat you have out-of-sample data to test the performance of your model.\n\n3. Loading the data\n===================\n\nNow that we have access to the dataset, we must pass it through\n``torch.utils.data.DataLoader``. The ``DataLoader`` combines the dataset\nand a sampler, returning an iterable over the dataset.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_loader = torch.utils.data.DataLoader(yesno_data,\n                                          batch_size=1,\n                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Iterate over the data\n========================\n\nOur data is now iterable using the ``data_loader``. This will be\nnecessary when we begin training our model! You will notice that now\neach data entry in the ``data_loader`` object is converted to a tensor\ncontaining tensors representing our waveform, sample rate, and labels.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for data in data_loader:\n  print(\"Data: \", data)\n  print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(data[0], data[1], data[2]))\n  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. [Optional] Visualize the data\n================================\n\nYou can optionally visualize your data to further understand the output\nfrom your ``DataLoader``.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nprint(data[0][0].numpy())\n\nplt.figure()\nplt.plot(waveform.t().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Congratulations! You have successfully loaded data in PyTorch.\n\nLearn More\n----------\n\nTake a look at these other recipes to continue your learning:\n\n-  ``Defining a Neural Network <https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html>``\\ \\_\\_\n-  ``What is a state_dict in PyTorch <https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html>``\\ \\_\\_\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}