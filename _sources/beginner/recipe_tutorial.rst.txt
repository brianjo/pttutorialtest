.. note::
    :class: sphx-glr-download-link-note

    Click :ref:`here <sphx_glr_download_beginner_recipe_tutorial.py>` to download the full example code
.. rst-class:: sphx-glr-example-title

.. _sphx_glr_beginner_recipe_tutorial.py:


Loading data in PyTorch
=======================

PyTorch features extensive neural network building blocks with a simple,
intuitive, and stable API. PyTorch includes packages to prepare and load
common datasets for your model.

Introduction
------------

At the heart of PyTorch data loading utility is the
``torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader>``\ **class.
It represents a Python iterable over a dataset. Libraries in PyTorch
offer built-in high-quality datasets for you to use in
``torch.utils.data.Dataset <https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset>``**.
These datasets are currently available in:

-  ``torchvision <https://pytorch.org/docs/stable/torchvision/datasets.html>``\ \_\_
-  ``torchaudio <https://pytorch.org/audio/datasets.html>``\ \_\_
-  ``torchtext <https://pytorch.org/text/datasets.html>``\ \_\_

with more to come. Using the Yesno dataset from
``torchaudio.datasets.YESNO``, we will demonstrate how to effectively
and efficiently load data from a PyTorch ``Dataset`` into a PyTorch
``DataLoader``.

Setup
-----

Before we begin, we need to install ``torchaudio`` to have access to the
dataset.

::

      pip install torchaudio

.. code-block:: default


    # %matplotlib inline








Steps
-----

1. Import all necessary libraries for loading our data
2. Access the data in the dataset
3. Loading the data
4. Iterate over the data
5. [Optional] Visualize the data


1. Import necessary libraries for loading our data
==================================================

For this recipe, we will use ``torch`` and ``torchaudio``. Depending on
what built-in datasets you use, you can also install and import
``torchvision`` or ``torchtext``.



.. code-block:: default


    # Uncomment the line below to enable this in Google Colab
    # !pip install torch torchaudio torchvision torchtext

    import torch
    import torchaudio








2. Access the data in the dataset
=================================

The Yesno dataset in ``torchaudio`` features sixty recordings of one
individual saying yes or no in Hebrew; with each recording being eight
words long (``read more here <https://www.openslr.org/1/>``\ \__).

``torchaudio.datasets.YESNO`` creates a dataset for YesNo.

.. code:: python

      torchaudio.datasets.YESNO(
        root,
        url='http://www.openslr.org/resources/1/waves_yesno.tar.gz',
        folder_in_archive='waves_yesno',
        download=False,
        transform=None,
        target_transform=None)

Each item in the dataset is a tuple of the form: (waveform, sample_rate,
labels).

You must set a ``root`` for the Yesno dataset, which is where the
training and testing dataset will exist. The other parameters are
optional, with their default values shown. Here is some additional
useful info on the other parameters:


-  ``download``: If true, downloads the dataset from the internet and
   puts it in root directory. If dataset is already downloaded, it is
   not downloaded again.
-  ``transform``: Using transforms on your data allows you to take it
   from its source state and transform it into data that’s joined
   together, de-normalized, and ready for training. Each library in
   PyTorch supports a growing list of transformations.
-  ``target_transform``: A function/transform that takes in the target
   and transforms it.

Let’s access our Yesno data:

A data point in Yesno is a tuple (waveform, sample_rate, labels) where
labels is a list of integers with 1 for yes and 0 for no.



.. code-block:: default


    yesno_data = torchaudio.datasets.YESNO('./', download=True)








Pick data point number 3 to see an example of the the yesno_data:



.. code-block:: default


    n = 3
    waveform, sample_rate, labels = yesno_data[n]
    print("Waveform: {}\nSample rate: {}\nLabels: {}".format(waveform, sample_rate, labels))






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Waveform: tensor([[ 3.0518e-05,  6.1035e-05,  3.0518e-05,  ..., -1.8311e-04,
              4.2725e-04,  6.7139e-04]])
    Sample rate: 8000
    Labels: [0, 0, 1, 0, 0, 0, 1, 0]


When using this data in practice, it is best practice to provision the
data into a “training” dataset and a “testing” dataset. This ensures
that you have out-of-sample data to test the performance of your model.

3. Loading the data
===================

Now that we have access to the dataset, we must pass it through
``torch.utils.data.DataLoader``. The ``DataLoader`` combines the dataset
and a sampler, returning an iterable over the dataset.



.. code-block:: default


    data_loader = torch.utils.data.DataLoader(yesno_data,
                                              batch_size=1,
                                              shuffle=True)








4. Iterate over the data
========================

Our data is now iterable using the ``data_loader``. This will be
necessary when we begin training our model! You will notice that now
each data entry in the ``data_loader`` object is converted to a tensor
containing tensors representing our waveform, sample rate, and labels.



.. code-block:: default


    for data in data_loader:
      print("Data: ", data)
      print("Waveform: {}\nSample rate: {}\nLabels: {}".format(data[0], data[1], data[2]))
      break






.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Data:  [tensor([[[3.0518e-05, 6.1035e-05, 3.0518e-05,  ..., 2.5024e-03,
              1.9531e-03, 2.2278e-03]]]), tensor([8000]), [tensor([0]), tensor([1]), tensor([0]), tensor([1]), tensor([1]), tensor([0]), tensor([1]), tensor([0])]]
    Waveform: tensor([[[3.0518e-05, 6.1035e-05, 3.0518e-05,  ..., 2.5024e-03,
              1.9531e-03, 2.2278e-03]]])
    Sample rate: tensor([8000])
    Labels: [tensor([0]), tensor([1]), tensor([0]), tensor([1]), tensor([1]), tensor([0]), tensor([1]), tensor([0])]


5. [Optional] Visualize the data
================================

You can optionally visualize your data to further understand the output
from your ``DataLoader``.



.. code-block:: default


    import matplotlib.pyplot as plt

    print(data[0][0].numpy())

    plt.figure()
    plt.plot(waveform.t().numpy())





.. image:: /beginner/images/sphx_glr_recipe_tutorial_001.png
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [[3.0517578e-05 6.1035156e-05 3.0517578e-05 ... 2.5024414e-03
      1.9531250e-03 2.2277832e-03]]


Congratulations! You have successfully loaded data in PyTorch.

Learn More
----------

Take a look at these other recipes to continue your learning:

-  ``Defining a Neural Network <https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html>``\ \_\_
-  ``What is a state_dict in PyTorch <https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html>``\ \_\_



.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  1.799 seconds)


.. _sphx_glr_download_beginner_recipe_tutorial.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download

     :download:`Download Python source code: recipe_tutorial.py <recipe_tutorial.py>`



  .. container:: sphx-glr-download

     :download:`Download Jupyter notebook: recipe_tutorial.ipynb <recipe_tutorial.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.readthedocs.io>`_
